Nice, this is actually good progress â€” the pipeline is doing the right thing now and only dying on a memory issue:

numpy.core._exceptions._ArrayMemoryError: Unable to allocate 19.1 GiB for an array with shape (91, 2, 14065377) and data type float64

Thatâ€™s coming from:

h5_data_reader.laplacian_rereference â†’ filter_data â†’ notch_filter â†’ signal.lfilter(...)


So:
PopT is loading all 91 electrodes Ã— 2 neighbors Ã— 14M samples for the entire trial at 2,048 Hz, in float64, and then applying a notch filter. That single array is ~19 GB â†’ your 32 GB machine chokes.

We donâ€™t need fancy rereferencing to just get a working baseline on sub_1 / trial000 & 002, so the easiest fix is:

Disable laplacian rereferencing for this run â†’ no giant filtered array â†’ no 19 GB allocation.

We can do this purely via Hydra override, no file edits needed.

SOLUTION "++data.rereference=None"

That should:

skip laplacian reref,

avoid the 19 GB filter allocation,

finish writing features for trial000 and then trial002.

ISSUE 2 

The new error:

numpy.core._exceptions._ArrayMemoryError: Unable to allocate 51.1 GiB for an array with shape (7356, 91, 10240)


is happening here:

all_word_samples = np.stack([filtered_data[:, start:end] for (start,end) in word_intervals])


So for trial000 itâ€™s trying to build:

7,356 intervals

Ã— 91 electrodes

Ã— 10,240 samples (â‰ˆ 5 seconds at 2048 Hz)

in float64 â†’ ~51 GB just for this stack ðŸ˜µ

On a 32 GB laptop, thatâ€™s never going to fly with the full official config.

To still get a PopT word-onset baseline on your box, weâ€™ll:

Turn off rereference âœ… (already did, rereference=None)

Shrink the window duration (5s â†’ 1s)

Subsample the number of intervals (e.g., use ~10% of them)

This gives you a smaller but faithful version of the official pipeline: same code path, just fewer/shorter windows.

