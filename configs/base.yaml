data:
  # === PopT speech baseline ===
  use_popt_speech: true

  # Root of all_test_word_onset generated by PopT
  brain_root_speech: "C:/Users/badri/OneDrive/Documents/EE 675 Neural Learning/Baseline Replication/PopulationTransformer/saved_examples/all_test_word_onset_idx07"

  # PopT-generated files
  speech_manifest_tsv: "C:/Users/badri/OneDrive/Documents/EE 675 Neural Learning/Baseline Replication/PopulationTransformer/saved_examples/all_test_word_onset_idx07/manifest.tsv"
  speech_labels_tsv:   "C:/Users/badri/OneDrive/Documents/EE 675 Neural Learning/Baseline Replication/PopulationTransformer/saved_examples/all_test_word_onset_idx07/labels.tsv"
  
  split_mode: "by_trial"  
  train_frac: 1.0
  # only_subjects: ["sub_1", "sub_2"]

  # random gave 0.96 AUC
  # split_mode: "random"
  # train_frac: 0.9
  # only_subjects: ["sub_1"]

  train_subject_trials:
    - subject: "sub_1"
      trials: ["trial000"]

  val_subject_trials:
    - subject: "sub_1"
      trials: ["trial002"]

model:
  popt_cfg_path: "C:/Users/badri/OneDrive/Documents/EE 675 Neural Learning/Baseline Replication/PopulationTransformer/conf/model/pt_custom_model.yaml"
  d_model: 512
  n_heads: 8
  num_layers: 6
  d_contrastive: 64
  dropout: 0.1

  brain_input_dim: 768
  coord_dim: 0

  # audio_* fields are ignored in brain_only mode but can stay
  audio_d_model: 128
  audio_hidden_dim: 256
  audio_num_layers: 3
  audio_kernel_size: 5
  audio_dropout: 0.1

  # === PopT downstream (Option A) ===
  # upstream_path: "C:/Users/badri/OneDrive/Documents/EE 675 Neural Learning/Baseline Replication/Brain-Treebank/pretrained_weights/popt_pretrained_weights/pretrained_popt_brainbert_stft.pth"
  popt_cfg_path: "C:/Users/badri/OneDrive/Documents/EE 675 Neural Learning/Baseline Replication/Brain-Treebank/pretrained_weights/popt_pretrained_weights/pt_downstream_model.yaml"
  popt_upstream_path: "C:/Users/badri/OneDrive/Documents/EE 675 Neural Learning/Baseline Replication/Brain-Treebank/pretrained_weights/popt_pretrained_weights/pretrained_popt_brainbert_stft.pth"
  # freeze_brain: false    # let it adapt to speech task
  use_popt_downstream: true

training:
  batch_size: 64
  epochs: 20
  lr: 1e-5
  weight_decay: 1e-2
  temperature: 0.07

  lambda_cls: 1.0
  lambda_smooth: 0.0     # no smoothing for pure baseline

  device: "cuda"
  seed: 42
  num_workers: 4
  brain_only: true        # <-- CRUCIAL

logging:
  log_interval: 50
  val_interval: 1
  ckpt_dir: "./checkpoints_popt_speech"
